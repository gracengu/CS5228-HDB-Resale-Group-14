{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from preprocessing_train_test import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.stats import skew \n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "pd.set_option('display.max_columns', 100)  # 设置显示100列\n",
    "pd.set_option('display.max_rows', 100)   # 设置显示100行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = \"../data/backup/merge_auxiliary_data_train.csv\"\n",
    "file_path_test = \"../data/backup/merge_auxiliary_data_test.csv\"\n",
    "\n",
    "train_gdf = pd.read_csv(file_path_train)\n",
    "test_gdf = pd.read_csv(file_path_test)\n",
    "\n",
    "print(\"train dataset shape: \", train_gdf.shape)\n",
    "print(\"test dataset shape: \",test_gdf.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [6, 7, 8, 9]\n",
    "min_child_weights = [1.2, 1.3, 1.4]\n",
    "reg_alphas = [1.5, 1.6, 1.7] \n",
    "reg_lambdas = [1.5, 1.55, 1.6]\n",
    "\n",
    "scores_xgb = {}\n",
    "for max_depth in max_depths:\n",
    "    for min_child_weight in min_child_weights:\n",
    "        for reg_alpha in reg_alphas:\n",
    "            for reg_lambda in reg_lambdas:\n",
    "                print('start training with max_depth: {}, min_child_weight: {}, reg_alpha: {}, reg_lambda: {}'.format(max_depth, min_child_weight, reg_alpha, reg_lambda))\n",
    "                mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "                split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "                for idx, (train_idx, validate_idx) in enumerate(split):\n",
    "                    print('fold {}'.format(idx + 1))\n",
    "                    train_df, validate_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(validate_idx)])\n",
    "\n",
    "                    x_train, y_train = train_df.drop(columns=[\"resale_price\"], errors='ignore'), train_df[\"resale_price\"]\n",
    "                    x_valid, y_valid = validate_df.drop(columns=[\"resale_price\"], errors='ignore'), validate_df[\"resale_price\"]\n",
    "\n",
    "                    features = pd.concat([x_train, x_valid]).reset_index(drop=True)\n",
    "                    # overfit = []\n",
    "                    # for i in features.columns:\n",
    "                    #     counts = features[i].value_counts()\n",
    "                    #     zeros = counts.iloc[0]\n",
    "                    #     if zeros / len(features) * 100 > 99.94:\n",
    "                    #         overfit.append(i)\n",
    "\n",
    "                    # overfit = list(overfit)\n",
    "                    final_features = features.drop(columns=['primary_id', 'second_id', 'mall_id'], axis=1)\n",
    "                    # final_features = features.drop(columns=overfit, axis=1)\n",
    "                    # final_features = features.iloc[:, :60]\n",
    "\n",
    "                    x_train = final_features.iloc[:len(x_train), :]\n",
    "                    x_valid = final_features.iloc[len(x_train):, :]\n",
    "\n",
    "                    regressor = xgb.XGBRegressor(n_estimators=1400, max_depth=max_depth, min_child_weight=min_child_weight, reg_alpha=reg_alpha, reg_lambda=reg_lambda, subsample=1, n_jobs=3).fit(x_train, y_train)\n",
    "                    \n",
    "                    y_train_predict = regressor.predict(x_train)\n",
    "                    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "                    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "                    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "                    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "                    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "\n",
    "                print(mae_test, mae_valid, mse_test, mse_valid)\n",
    "                scores_xgb[(max_depth, min_child_weight, reg_alpha, reg_lambda)] = (mae_test, mae_valid, mse_test, mse_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae_key, min_mae = None, 100000\n",
    "min_mse_key, min_mse = None, 10000000000000\n",
    "for key, (_, mae_valid, _, mse_valid) in scores_xgb.items():\n",
    "    if np.mean(mae_valid) < min_mae:\n",
    "        min_mae_key = key\n",
    "        min_mae = np.mean(mae_valid)\n",
    "    if np.mean(mse_valid) < min_mse:\n",
    "        min_mse_key = key\n",
    "        min_mse = np.mean(mse_valid)\n",
    "print(min_mae_key, min_mae)\n",
    "print(min_mse_key, min_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run best random forest hyperparam on full dataset'''\n",
    "test_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "train_df, test_df = preprocess_train_test(train_gdf, test_gdf)\n",
    "\n",
    "x_train, y_train = train_df.drop(columns=[\"resale_price\"], errors='ignore'), train_df[\"resale_price\"]\n",
    "features = pd.concat([x_train, test_df])\n",
    "\n",
    "# features_tmp = features\n",
    "features_tmp = features.iloc[:, :60]\n",
    "# features_tmp = features.drop(columns=['distance_to_mrt_bins_price', 'mrt_lrt_links', 'population_bins_price', 'adult_children_ratio_bins_price', 'mrt_interchange_flag', 'mrt_interchange_count', 'mrt_type_price'], errors='ignore')\n",
    "# features_tmp = features.drop(columns=['distance_to_mrt_bins_price', 'mrt_lrt_links', 'population_bins_price'], errors='ignore')\n",
    "\n",
    "x_train = features_tmp.iloc[:len(train_df), :]\n",
    "x_test = features_tmp.iloc[len(train_df):, :]\n",
    "\n",
    "\n",
    "regressor = xgb.XGBRegressor(n_estimators=1300, max_depth=6, min_child_weight=1.3, reg_alpha=1.6, reg_lambda=1.5, n_jobs=3).fit(x_train, y_train)\n",
    "# regressor = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "#                              learning_rate=0.05, max_depth=6, \n",
    "#                              min_child_weight=1.5, n_estimators=500,\n",
    "#                              reg_alpha=1, reg_lambda=0.8571,\n",
    "#                              subsample=0.5213, nthread = -1).fit(x_train, y_train)\n",
    "\n",
    "y_train_predict = regressor.predict(x_train)\n",
    "# y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "print(mean_absolute_error(y_train, y_train_predict))\n",
    "# mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "print(mean_squared_error(y_train, y_train_predict))\n",
    "# mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "\n",
    "# compute feature importances using the Gini importance method\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# get the indices of the top 10 most important features\n",
    "idx = importances.argsort()[-10:]\n",
    "print(importances)\n",
    "\n",
    "# plot the top 10 features\n",
    "plt.bar(range(len(idx)), importances[idx])\n",
    "plt.xticks(range(len(idx)), features_tmp.columns[idx], rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = regressor.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Predicted\": y_test_predict\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"PredictedPrice.csv\", index=True, index_label=\"Id\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves = [4, 6]\n",
    "max_bins = [100, 200]\n",
    "bagging_fractions = [0.7, 0.8] \n",
    "bagging_freqs = [3, 10]\n",
    "\n",
    "# num_leaves = [4]\n",
    "# max_bins = [100, 400]\n",
    "# bagging_fractions = [0.75] \n",
    "# bagging_freqs = [3]\n",
    "\n",
    "scores_lightgbm = {}\n",
    "for num_leave in num_leaves:\n",
    "    for max_bin in max_bins:\n",
    "        for bagging_fraction in bagging_fractions:\n",
    "            for bagging_freq in bagging_freqs:\n",
    "                print('start training with num_leave: {}, max_bin: {}, bagging_fraction: {}, bagging_freq: {}'.format(num_leave, max_bin, max_bin, bagging_fraction))\n",
    "                mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "                split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "                for idx, (train_idx, validate_idx) in enumerate(split):\n",
    "                    print('fold {}'.format(idx + 1))\n",
    "                    train_df, validate_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(validate_idx)])\n",
    "\n",
    "                    x_train, y_train = train_df.drop(columns=[\"resale_price\"], errors='ignore'), train_df[\"resale_price\"]\n",
    "                    x_valid, y_valid = validate_df.drop(columns=[\"resale_price\"], errors='ignore'), validate_df[\"resale_price\"]\n",
    "\n",
    "                    features = pd.concat([x_train, x_valid]).reset_index(drop=True)\n",
    "                    overfit = []\n",
    "                    for i in features.columns:\n",
    "                        counts = features[i].value_counts()\n",
    "                        zeros = counts.iloc[0]\n",
    "                        if zeros / len(features) * 100 > 99.94:\n",
    "                            overfit.append(i)\n",
    "\n",
    "                    overfit = list(overfit)\n",
    "                    final_features = features.drop(overfit, axis=1)\n",
    "\n",
    "                    x_train = final_features.iloc[:len(x_train), :]\n",
    "                    x_valid = final_features.iloc[len(x_train):, :]\n",
    "\n",
    "                    regressor = LGBMRegressor(objective='regression', \n",
    "                                                n_estimators=300,\n",
    "                                                num_leaves=num_leave,\n",
    "                                                max_bin=max_bin, \n",
    "                                                learning_rate=0.01, \n",
    "                                                bagging_fraction=bagging_fraction,\n",
    "                                                bagging_freq=bagging_freq, \n",
    "                                                bagging_seed=7,\n",
    "                                                feature_fraction=0.2,\n",
    "                                                feature_fraction_seed=7).fit(x_train, y_train)                    \n",
    "                    y_train_predict = regressor.predict(x_train)\n",
    "                    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "                    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "                    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "                    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "                    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "\n",
    "                print(mae_test, mae_valid, mse_test, mse_valid)\n",
    "                scores_lightgbm[(max_depth, min_child_weight, reg_alpha, reg_lambda)] = (mae_test, mae_valid, mse_test, mse_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run best random forest hyperparam on full dataset'''\n",
    "test_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "train_df, test_df = preprocess_train_test(train_gdf, test_gdf)\n",
    "\n",
    "x_train, y_train = train_df.drop(columns=[\"resale_price\"], errors='ignore'), train_df[\"resale_price\"]\n",
    "\n",
    "# x_valid, y_valid = validate_df.drop(columns=drop_columns, errors='ignore'), validate_df[\"resale_price\"]\n",
    "\n",
    "regressor = LGBMRegressor(objective='regression', \n",
    "                            n_estimators=500,\n",
    "                            num_leaves=num_leave,\n",
    "                            max_bin=max_bin, \n",
    "                            learning_rate=0.01, \n",
    "                            bagging_fraction=bagging_fraction,\n",
    "                            bagging_freq=bagging_freq, \n",
    "                            bagging_seed=7,\n",
    "                            feature_fraction=0.2,\n",
    "                            feature_fraction_seed=7).fit(x_train, y_train)\n",
    "y_train_predict = regressor.predict(x_train)\n",
    "# y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "print(mean_absolute_error(y_train, y_train_predict))\n",
    "# mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "print(mean_squared_error(y_train, y_train_predict))\n",
    "# mse_valid.append(mean_squared_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae_key, min_mae = None, 100000\n",
    "min_mse_key, min_mse = None, 10000000000000\n",
    "for key, (_, mae_valid, _, mse_valid) in scores_lightgbm.items():\n",
    "    if np.mean(mae_valid) < min_mae:\n",
    "        min_mae_key = key\n",
    "        min_mae = np.mean(mae_valid)\n",
    "    if np.mean(mse_valid) < min_mse:\n",
    "        min_mse_key = key\n",
    "        min_mse = np.mean(mse_valid)\n",
    "print(min_mae_key, min_mae)\n",
    "print(min_mse_key, min_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
