{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from preprocessing_train_test import *\n",
    "pd.set_option('display.max_columns', 100)  # 设置显示100列\n",
    "pd.set_option('display.max_rows', 100)   # 设置显示100行\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = \"../data/backup/merge_auxiliary_data_train.csv\"\n",
    "file_path_test = \"../data/backup/merge_auxiliary_data_test.csv\"\n",
    "\n",
    "train_gdf = pd.read_csv(file_path_train)\n",
    "test_gdf = pd.read_csv(file_path_test)\n",
    "\n",
    "print(\"train dataset shape: \", train_gdf.shape)\n",
    "print(\"test dataset shape: \",test_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "test_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "drop_columns = [\n",
    "    \"resale_price\",\n",
    "    \"town\",\n",
    "    \"block\",\n",
    "    \"flat_type\",\n",
    "    \"street_name\",\n",
    "    \"storey_range\",\n",
    "    \"flat_model\",\n",
    "    \"eco_category\",\n",
    "    \"lease_commence_date\",\n",
    "    \"elevation\",\n",
    "    \"subzone\",\n",
    "    \"planning_area\",\n",
    "    \"region\",\n",
    "    \"mrt_name\",\n",
    "    \"mrt_type\",\n",
    "    \"codes\",\n",
    "    \"codes_name\",\n",
    "    \"type_commerical\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAVG(list_num):\n",
    "    return sum(list_num) / len(list_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    \n",
    "    # Standardlize the data feature\n",
    "    scaler = MinMaxScaler()\n",
    " \n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    x_valid = pd.DataFrame(scaler.transform(x_valid), columns = x_valid.columns)\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    \n",
    "    \n",
    "    regressor = Lasso(alpha=1.0, fit_intercept=True, max_iter = 500)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Create a Lasso model\n",
    "model = Lasso()\n",
    "\n",
    "# Perform a grid search over the hyperparameter grid using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=2)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    \n",
    "    # {'alpha': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'normalize': False}\n",
    "    regressor = Ridge(alpha = 0.01, fit_intercept=True, max_iter = 1000, normalize = False)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "    \n",
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5228_hdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
