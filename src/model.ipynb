{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from preprocessing_train_test import *\n",
    "pd.set_option('display.max_columns', 100)  # 设置显示100列\n",
    "pd.set_option('display.max_rows', 100)   # 设置显示100行\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = \"../data/backup/merge_auxiliary_data_train.csv\"\n",
    "file_path_test = \"../data/backup/merge_auxiliary_data_test.csv\"\n",
    "\n",
    "train_gdf = pd.read_csv(file_path_train)\n",
    "test_gdf = pd.read_csv(file_path_test)\n",
    "\n",
    "print(\"train dataset shape: \", train_gdf.shape)\n",
    "print(\"test dataset shape: \",test_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening year has lots of nan values. why?\n",
    "train_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "test_gdf.drop(columns=[\"opening_year\"], inplace=True, errors='ignore')\n",
    "drop_columns = [\n",
    "    \"resale_price\",\n",
    "    \"town\",\n",
    "    \"block\",\n",
    "    \"flat_type\",\n",
    "    \"street_name\",\n",
    "    \"storey_range\",\n",
    "    \"flat_model\",\n",
    "    \"eco_category\",\n",
    "    \"lease_commence_date\",\n",
    "    \"elevation\",\n",
    "    \"subzone\",\n",
    "    \"planning_area\",\n",
    "    \"region\",\n",
    "    \"mrt_name\",\n",
    "    \"mrt_type\",\n",
    "    \"codes\",\n",
    "    \"codes_name\",\n",
    "    \"type_commerical\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get once fold of training and testing data\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"].astype(int)\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"].astype(int)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train_shape\", x_train.shape)\n",
    "print(\"y_train_shape\", y_train.shape)\n",
    "print(\"x_valid_shape\", x_valid.shape)\n",
    "print(\"y_valid_shape\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "param_grid = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(x_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "print(\"MAE on testing set: \", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    break\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Standardlize the data feature\n",
    "scaler = MinMaxScaler()\n",
    "train_df = pd.DataFrame(scaler.fit_transform(train_df), columns=train_df.columns)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    \n",
    "    # Standardlize the data feature\n",
    "    scaler = MinMaxScaler()\n",
    " \n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    x_valid = pd.DataFrame(scaler.transform(x_valid), columns = x_valid.columns)\n",
    "    \n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAVG(list_num):\n",
    "    return sum(list_num) / len(list_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "# param_grid = {\n",
    "#     'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "#     'fit_intercept': [True, False],\n",
    "#     'normalize': [True, False],\n",
    "#     'max_iter': [100, 500, 1000],\n",
    "# }\n",
    "\n",
    "# Create a Lasso model\n",
    "model = Lasso(alpha=1.0, fit_intercept=True, max_iter = 500)\n",
    "\n",
    "# # Perform a grid search over the hyperparameter grid using 5-fold cross-validation\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    \n",
    "    \n",
    "    regressor = Lasso(alpha=1.0, fit_intercept=True, max_iter = 500)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "#     'fit_intercept': [True, False],\n",
    "#     'normalize': [True, False],\n",
    "#     'max_iter': [100, 500, 1000],\n",
    "# }\n",
    "\n",
    "# # Create a Lasso model\n",
    "# model = Lasso()\n",
    "\n",
    "# # Perform a grid search over the hyperparameter grid using 5-fold cross-validation\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=2)\n",
    "\n",
    "# # Fit the grid search to the training data\n",
    "# grid_search.fit(x_train, y_train)\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    \n",
    "    # {'alpha': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'normalize': False}\n",
    "    regressor = Ridge(alpha = 0.01, fit_intercept=True, max_iter = 1000, normalize = False)\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "    \n",
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = {}\n",
    "# for alpha in param_grid['alpha']:\n",
    "#     for fit_intercept in param_grid['fit_intercept']:\n",
    "#         for normalize in param_grid['normalize']:\n",
    "#             for max_iter in param_grid['max_iter']:\n",
    "#                 print('start training with alpha: {}, fit_intercept: {}, normalize: {}, max_iter: {}'.format(v, fit_intercept, normalize, max_iter))\n",
    "#                 mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "#                 split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "#                 for idx, (train_idx, test_idx) in enumerate(split):\n",
    "#                     print('fold {}'.format(idx + 1))\n",
    "#                     train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "\n",
    "#                     x_train, y_train = train_df.drop(columns=[\"resale_price\"], errors='ignore'), train_df[\"resale_price\"]\n",
    "#                     x_valid, y_valid = test_df.drop(columns=[\"resale_price\"], errors='ignore'), test_df[\"resale_price\"]\n",
    "\n",
    "#                     regressor = Ridge(alpha = alpha, fit_intercept = fit_intercept, normalize = normalize, max_iter = max_iter).fit(x_train, y_train)\n",
    "#                     y_train_predict = regressor.predict(x_train)\n",
    "#                     y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "#                     mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "#                     mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "#                     mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "#                     mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "\n",
    "#                 result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "#                 scores[(max_depth, max_feature, min_samples_split, min_samples_leaf)] = result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGBoost Regressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "mae_test, mae_valid, mse_test, mse_valid = [], [], [], []\n",
    "split = KFold(n_splits=5, shuffle=True).split(train_gdf)\n",
    "for idx, (train_idx, test_idx) in enumerate(split):\n",
    "    train_df, test_df = preprocess_train_test(train_gdf.iloc[list(train_idx)], train_gdf.iloc[list(test_idx)])\n",
    "    \n",
    "    # Standardlize the data feature\n",
    "    scaler = StandardScaler()\n",
    " \n",
    "    x_train, y_train = train_df.drop(columns=drop_columns, errors='ignore'), train_df[\"resale_price\"]\n",
    "    x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "\n",
    "    x_valid, y_valid = test_df.drop(columns=drop_columns, errors='ignore'), test_df[\"resale_price\"]\n",
    "    x_valid = pd.DataFrame(scaler.transform(x_valid), columns = x_valid.columns)\n",
    "    \n",
    "    regressor = XGBRegressor()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_predict = regressor.predict(x_train)\n",
    "    y_valid_predict = regressor.predict(x_valid)\n",
    "\n",
    "    mae_test.append(mean_absolute_error(y_train, y_train_predict))\n",
    "    mae_valid.append(mean_absolute_error(y_valid, y_valid_predict))\n",
    "    mse_test.append(mean_squared_error(y_train, y_train_predict))\n",
    "    mse_valid.append(mean_squared_error(y_valid, y_valid_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [getAVG(i) for i in [mae_test, mae_valid, mse_test, mse_valid]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5228_hdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
